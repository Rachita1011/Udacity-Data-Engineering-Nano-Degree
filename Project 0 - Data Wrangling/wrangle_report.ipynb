{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Udacity Project - Data Wrangling\n",
    "### Data Wrangling Report \n",
    "#### Rachita R. Puri "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to use Python and its libraries to gather data from a variety of sources in different formats and learn to assess its quality and tidiness and then clean it. This is because real world data rarely comes clean and correctly formatted and therefore we should be familiar with how to complete the data wrangling process.\n",
    "\n",
    "This project requires us to analyse data from the Twitter user WeRateDogs. WeRateDogs is a Twitter accounts that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three data sources will be used as part of the project. \n",
    "\n",
    "**1. The WeRateDogs Twitter Archive (Enhanced Twitter Archive)**\n",
    "\n",
    "This file consists of the tweets archive of the WeRateDogs twitter user. The archive concsists of basic tweet data (for example tweet ID, timestamp, text, etc.) for all 5000+ tweets as they stood on August 1st 2017.\n",
    "\n",
    "**2. Image Predictions File**\n",
    "\n",
    "A neural network was created that helped classify the breeds of dogs. As part of the project we were provided with a file where every image in the WeRateDogs Twitter archive has been run through this neual network. The image predictions file is a table which predicts the top 3 breeds the dog in the image could possibly be; along with confidence intervals as to how confident it is that the dog in the image is that specific breed. It also contains the tweet ID for each image as well as the image url.\n",
    "\n",
    "**3. Data Downloaded from the Twitter API (Retweets/Favourite Counts)**\n",
    "\n",
    "The last data source consisted of us creating a developer account on Twitter to be able to download the data from the Twitter API. The Twitter API enabled us to download the 3000 most recent tweets. I was able to download from the API the retweet count and favourites count which was useful in creating the insights in the analysis report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the project we were required to analyse all three datasets visually and programmatically to understand the issues with the data. The requirement was that we find a minimum of 8 quality issues in the data and 2 tidiness issues which we wil be required to fix within the cleaning process.\n",
    "\n",
    "#### Quality Issues\n",
    "\n",
    "**1. Enhanced Twitter Archive**\n",
    "\n",
    "| Issue Number | Issue Details |\n",
    "|---|---|\n",
    "| Issue 2 | Name column contains incorrect names such as(i.e. a, an Bo, My). Some names are also appearing as None. |\n",
    "| Issue 3 | The source column is still including the html tags in the rows of data. |\n",
    "| Issue 11 | There are rows of data where denominator is not 10. This needs to be changed. |\n",
    "\n",
    "\n",
    "**2. Image Prediction File**\n",
    "\n",
    "| Issue Number | Issue Details |\n",
    "|---|---|\n",
    "| Issue 6 | Remove the underscores in the dog breed columns P1, P2 and P3. |\n",
    "| Issue 7 | Remove the rows where P1_dog, P2_dog or P3_dog appear as False. |\n",
    "| Issue 8 | Delete the 66 jpg_urls that are duplicated in the table. | \n",
    "| Issue 9 | Combine all dog breed names and confidence interval columns into one column for each. |\n",
    "\n",
    "**3. Twitter API Data**\n",
    "\n",
    "| Issue Number | Issue Details |\n",
    "|---|---|\n",
    "| Issue 10 | Only keep the original tweets |\n",
    "\n",
    "#### Tidiness Issues\n",
    "\n",
    "| Issue Number | Issue Details |\n",
    "|---|---|\n",
    "| Issue 1 | All the tables should be part of one dataset, therefore will need to be combined into one table. |\n",
    "| Issue 4 | Doggo, floofer, pupper, puppo should be combined to one column. |\n",
    "| Issue 5 | The tweet_id columns should be a string and not an integer. | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using different libraries in Python I was able to fix the quality issues with the three data sources. I intially combined all three data sources together and then performed the task of correcting the data quality issues and then when creating the final dataset I have dropped any unneccessary columns which would not be required to do the analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
