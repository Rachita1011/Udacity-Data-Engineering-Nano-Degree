# Project: Data Lake with Spark

## Introduction

A music streaming startup, Sparkify, has grown their user base and song database even more and want to move their data warehouse to a data lake. Their data resides in S3, in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.

## Purpose of this Project

The purpose of this project is to build an ETL pipelines that extracts the data from S3, processes them using Spark, and loads the data back into S3 as a set of dimensional tables. 

This will enable the analytics team to find further insights on the data and their usage. 

## Schema Design

The database schema design is in the form of a star schema. 

![This is an image](https://github.com/Rachita1011/Udacity-Data-Engineering-Nano-Degree/blob/main/Project%204%20-%20Data%20Lakes%20with%20Spark/Star%20Schema.PNG)

## How to Run the Pipeline

I have created a python script named etl.py which extracts the data from the S3 locations where the song and log datasets are stored and parses/inserts them into the local directory. 

To recreate the tables, you will need to run etl.py script.

## ELT Pipeline

There are two pipelines one for the song data and the other for the logs data.

The songs dataset is a subset of real data from the Million Song Dataset. Each file is in JSON format and contains metadata about a song and the artist of that song. Filepaths are as follows:

> song_data/A/B/C/TRABCEI128F424C983.json
> song_data/A/A/B/TRAABJL12903CDCF1A.json

And have been loaded in the following location in S3:

- **Song Data:** s3://udacity-dend/song_data

The logs dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate app activity logs from an imaginary music streaming app based on configuration settings. Filepaths are as follows:

> log_data/2018/11/2018-11-12-events.json
> log_data/2018/11/2018-11-13-events.json

And have been loaded in the following location in S3:

- **Log Data:** s3://udacity-dend/log_data

## Example Queries

Here are some example queries that can be used to analyse the data:

-Artist popularity: check which artists are being listened to more often.

    SELECT A.ARTIST_NAME, 
            COUNT(A.ARTIST_ID) AS TOTAL 
    FROM SONGPLAYS AS S 
    JOIN ARTISTS AS A 
    ON S.ARTIST_ID = A.ARTIST_ID 
    GROUP BY 1 
    ORDER BY TOTAL DESC

-Which users are using sparkify most in a specific month

    SELECT S.USER_ID, 
            EXTRACT(MONTH FROM S.START_TIME) AS MONTH, 
            COUNT(*) AS SONGS_PLAYED 
    FROM SONGPLAYS AS S 
    GROUP BY 1,2 
    ORDER BY MONTH, SONGS_PLAYED DESC`
